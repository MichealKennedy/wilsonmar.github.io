---
layout: post
title: "Beta Activities"
excerpt: "Not just for show."
tags: [beta, guava, java, programming]
image:
  feature: pic night bridge fast trails 1900x500.jpg
  credit: 
  creditlink: 
comments: true
---
<i>{{ page.excerpt }}</i>
<hr />

{% include _toc.html %}

The time during internal and public beta release reviews 
is often the first time that partners and friends have 
substantial hands-on experience with the upcoming version.

I think too many developers waste the opportunity
to build goodwill and real assistance that beta participants can provide.

### Define actors and use cases

   Too many organizations release only the software and
   expect everyone to just figure it out.

   This results in not enough coverage simply because people may not
   know about certain features.

   Clarification of who is being served and what they do would
   provide a richer jumping point for suggestions.

### Automation of use case flows

   Automation of keystrokes are useful not just for testing.

   Being able to run the demo sequence automatically would provide 
   <strong>salespeople and others confidence</strong> 
   that their live demo actually works
   rather than having to say sorry.

   Having automated use-case runs also helps to speed the development of
   <strong>product vidoes</strong> needed for not just launch but
   throughout the product lifecycle.

   The more people who views a video, 
   the more varied the extent of feedback.

### Capture detailed factual proof points

   General platitudes like "oh it's great" does a marketer no good.

   What are needed are "sound bites" and quotes that can be published.

   So we want to encourage beta reviewers to 
   take measurements before, during, and after demo activities.

   Valid measurements require planning and discipline,
   and that takes pre-planning and encouragement before and 
   all the way through the process.

### Detailed history of run speeds

   It would be useful to have timings captured during each automated run
   so that anomalies can be identified early,
   and comparisons have more data points over time and varying conditions.

   Then if somone complains that a particular run seemed slow,
   troubleshooting can include comparison against previous runs
   at various points in various environments.

### Help those who participated

   Many consultants make hay from the fact that they had a hand in the creation of
   the product.

   So have a webpage that acknowledges their participation so they can point to 
   proof that they mattered.

   Some beta participants had a fight to get approval for taking time to participate.

   So a letter or email to their bosses from one senior manager to another
   would go a long way to ensure continued enthusiam in the future.

   Such communication is an opportunity to "sell" the product,
   and contribute to continued willingness to pay maintenance fees.



> Let me help you! I've done this.

## More on Evanglism

This post is one of a (planned) series:

{% include evangelist_links.html %}

